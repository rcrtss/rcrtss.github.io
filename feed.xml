<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://rcrtss.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rcrtss.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-11T09:52:19+00:00</updated><id>https://rcrtss.github.io/feed.xml</id><title type="html">blank</title><subtitle>My personal portfolio based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">comparing performance of various search algorithms in a forward-planning agent</title><link href="https://rcrtss.github.io/blog/2024/hashnode-0/" rel="alternate" type="text/html" title="comparing performance of various search algorithms in a forward-planning agent"/><published>2024-12-02T12:00:00+00:00</published><updated>2024-12-02T12:00:00+00:00</updated><id>https://rcrtss.github.io/blog/2024/hashnode-0</id><content type="html" xml:base="https://rcrtss.github.io/blog/2024/hashnode-0/"><![CDATA[<p>After completing the Classical Planning project by coding the mutual exclusion methods for the classes <code class="language-plaintext highlighter-rouge">ActionLayer</code> and <code class="language-plaintext highlighter-rouge">LiteralLayer</code>, as well as the heuristic functions for the <code class="language-plaintext highlighter-rouge">PlanningGraph</code> class, a series of charts were created with the information obtained by running the four <strong>Air cargo problems</strong> on <code class="language-plaintext highlighter-rouge">run_search.py</code>.</p> <p>These charts were designed to compare between different search methods and heuristic functions, and analysing how the solution to each problem behaves when adding more actions to the problem.</p> <p>Three areas are evaluated in this report: complexity, search time and plan length. For each of these, different combinations of search methods, heuristics and problems were considered depending on what is analyzed. The following sections cover the results of each experiment with more detail.</p> <p>It is important to note that an optimization for efficiency in heuristics such as Max Level can be implemented to reduce times. This was not done for this report since it was optional, but it would be interesting to implement the optimizations and compare the results.</p> <h2 id="search-complexity">Search Complexity</h2> <p>The first thing to take into account is that the number of actions does not depend on the search method or heuristic function that is being used. For each problem, this number remains the same throughout every search method and heuristic.</p> <p>The first comparison was made for problems 1 and 2, for every uninformed search methods and all combination of informed methods with heuristics specified in the project description. <em>Figure 1</em> shows a line chart with the number of nodes expanded against the number of actions for a specific search method, for the first two problems (observe that the Y axis is represented with a log scale for better understanding of the behavior).</p> <p><img src="/assets/img/rubric_1_all-1-2-B.png" alt="Expansions vs Actions for problems 1 and 2" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <p>The second comparison (<em>Figure 2</em>) was done between the <code class="language-plaintext highlighter-rouge">uniform const search</code> as the only uninformed search method, and for the <code class="language-plaintext highlighter-rouge">greedy best first search</code> and the <code class="language-plaintext highlighter-rouge">A*</code> methods in combination with the <code class="language-plaintext highlighter-rouge">Level Sum</code> and the <code class="language-plaintext highlighter-rouge">Max Level</code> heuristics, for problems 3 and 4. Due to the time it takes to run the tests for these two problems, not all the heuristics were considered.</p> <p><img src="/assets/img/rubric_1_all-3-4.png" alt="Expansions vs Actions for problems 3 and 4 (Y-log)" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <p>In contrast to the first two charts, we see in <em>Figure 3</em> that analyzing the data with a linear Y scale reveals significant differences in the performance of various search methods.</p> <p><img src="/assets/img/rubric_1_3-4-nolog.png" alt="Expansions vs Actions for problems 3 and 4 (Y-linear)" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <h3 id="analysis">Analysis</h3> <p>In <em>Figure 1</em> we can see that for small problems (20 to 72 actions), <code class="language-plaintext highlighter-rouge">greedy best first</code> algorithm behaves significantly better, in terms of search complexity, with respect to the other methods. More specifically, the <code class="language-plaintext highlighter-rouge">greedy best first</code> with heuristics <code class="language-plaintext highlighter-rouge">Set Level</code> and <code class="language-plaintext highlighter-rouge">Level Sum</code> are the two methods that expand the fewest nodes in both problems 1 and 2. On the other hand, <code class="language-plaintext highlighter-rouge">breadth first</code> and <code class="language-plaintext highlighter-rouge">uniform cost</code> searches expand the most nodes when compared to other methods, for these two problems. Lastly, the <code class="language-plaintext highlighter-rouge">depth first</code> method and the rest of the informed search methods are located in the middleground of the chart (depending on which heuristic they use), but it already shows that they have a significantly higher complexity than the <code class="language-plaintext highlighter-rouge">greedy best first</code> search methods.</p> <p>Figures 2 and 3 show how some of these techniques behave when the problem gets more complicated. In <em>Figure 2</em> it is clear that, for the considered methods, the one that scales better is the <code class="language-plaintext highlighter-rouge">greedy best first</code> with <code class="language-plaintext highlighter-rouge">Level Sum</code> heuristic, followed by the same method with <code class="language-plaintext highlighter-rouge">Max Level</code> heuristic. On the other hand, the <code class="language-plaintext highlighter-rouge">uniform cost</code> and <code class="language-plaintext highlighter-rouge">A* with Max Level</code> methods scale at an exponential rate when the actions increase. <em>Figure 3</em> shows quite clearly how these two, but specially the <code class="language-plaintext highlighter-rouge">uniform cost</code> search method is significantly more inefficient than the rest of the methods in this comparison.</p> <h2 id="search-time">Search Time</h2> <p>For the next analysis, the time it took for computing each plan, by using different methods, was plotted in two charts. The first of them (<em>Figure 4</em>) depicts all methods for problems 1 and 2. The Y axis represents the elapsed time from the start of the algorithm to the end. This is represented in seconds in a logarithmic scale, for the values of <code class="language-plaintext highlighter-rouge">x1 = 20</code> and <code class="language-plaintext highlighter-rouge">x2 = 72</code>.</p> <p><img src="/assets/img/rubric_2_all-1-2.png" alt="Search Time (s) vs Actions for problems 1 and 2" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <p><em>Figure 5</em> considers the same methods than for <em>Figures 2 and 3</em>, and the problems 1 to 4. Again, the Y axis is in logarithmic scale and represents the time in seconds it took to compute each algorithm.</p> <p><img src="/assets/img/rubric_2_all-3-4.png" alt="Search Time (s) vs Actions for problems 3 and 4" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <p><img src="/assets/img/rubric_2_uninformed-log.png" alt="Search Time (s) vs Actions for problems 3 and 4 - Uninformed" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <h3 id="analysis-1">Analysis</h3> <p>By looking at both charts, we can see that the <code class="language-plaintext highlighter-rouge">A*</code> algorithms, specially with <code class="language-plaintext highlighter-rouge">Set Level</code> and <code class="language-plaintext highlighter-rouge">Max Level</code> heuristics are the two most time-expensive algorithms from this comparison. For <em>Figure 5</em>, the <code class="language-plaintext highlighter-rouge">Set Level</code> was not even considered due to the huge amount of time it took to solve problem 4. On the other hand, we can see that the least expensive of all algorithms was <code class="language-plaintext highlighter-rouge">greedy best first</code> with unmet heuristics, for problems 1 and 2. The uninformed search methods take much less time to compute than the informed methods, as seen in both figures, with the exception of <code class="language-plaintext highlighter-rouge">DFS</code>, as seen in <em>Figure 6</em>.</p> <h2 id="optimality-of-the-solution">Optimality of the solution</h2> <p>Finally, we analyze the optimality of the solutions by looking at the length of the plans outputted by each algorithm for the different problems and different heuristics. For the first two problems, since every method except for <code class="language-plaintext highlighter-rouge">DFS</code>, had the same number of actions for their solution, <em>Figure 7</em> compares only the depth first search against every other method. On the other hand, <em>Figure 8</em> takes into account the <code class="language-plaintext highlighter-rouge">uniform cost search</code> and the other four combinations of the informed searches used in previous sections.</p> <p><img src="/assets/img/rubric_3_all-1-2-B.png" alt="Plan Length vs Actions for problems 1 and 2" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <p><img src="/assets/img/rubric_3_all-3-4.png" alt="Plan Length vs Actions for problems 3 and 4" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <p><img src="/assets/img/rubric_3_uninformed.png" alt="Plan Length vs Actions for problems 3 and 4 - Uninformed" style="display: block; margin: 0 auto; max-width: 100%; height: auto;"/></p> <h3 id="analysis-2">Analysis</h3> <p>Looking at figures 7 to 9, we see that the least optimal solution is by far <code class="language-plaintext highlighter-rouge">DFS</code>. This was already expected due to the nature of this algorithm, and the fact that it does not guarantee to find the shortest path, (not mentioning that it is not even a <strong>complete</strong> search strategy). <em>Figure 9</em> shows clearly how DFS finds the least optimal solution when compared even to other uninformed strategies. Finally, in <code class="language-plaintext highlighter-rouge">Figure 8</code> we can see that the methods that find the most optimal plans for these experiments are <code class="language-plaintext highlighter-rouge">BFS</code>, <code class="language-plaintext highlighter-rouge">UCS</code> and <code class="language-plaintext highlighter-rouge">A* with Max Level heuristic</code>, while other informed methods, such as <code class="language-plaintext highlighter-rouge">greedy best first</code> with <code class="language-plaintext highlighter-rouge">Level Sum</code> and with <code class="language-plaintext highlighter-rouge">Max Level</code> heuristics (which were very optimal in terms of computation time and search complexity), have a weeker performance in terms of optimality in their solutions.</p> <h2 id="additional-questions">Additional Questions</h2> <p>Q: <strong>Which algorithm or algorithms would be most appropriate for planning in a very restricted domain (i.e., one that has only a few actions) and needs to operate in real time?</strong></p> <p>For problems with few actions, and for a real time application, I would use <code class="language-plaintext highlighter-rouge">greedy best first search</code> with the <code class="language-plaintext highlighter-rouge">unmet goals</code> heuristics, since according to the experiments, it behaves much better in terms of computation time than any of the other algorithms that were tested. While for problems that require more actions it may not find the most optimal solution, for small problems it did find an optimal solution, just as the best of the other algorithms.</p> <p>Q: <strong>Which algorithm or algorithms would be most appropriate for planning in very large domains (e.g., planning delivery routes for all UPS drivers in the U.S. on a given day)</strong></p> <p>For large domains, where computation resources may be available, I would probably choose between <code class="language-plaintext highlighter-rouge">A* with level sum or max level</code>, or an uninformed search like <code class="language-plaintext highlighter-rouge">UCS</code>. <code class="language-plaintext highlighter-rouge">A*</code>, specially with max level takes quite some time to compute, specially when the problem gets bigger, but it does find a more optimal solution, while not expanding as many nodes as BFS or UCS. UCS takes much less time to compute and finds an optimal solution as well, but with the drawback of expanding nodes that may not be relevant. Although, if an optimal solution is not required, I would go for a <code class="language-plaintext highlighter-rouge">greedy best first search</code> with level sum, which has the best of both worlds with the drawback of not finding an optimal solution.</p> <p>Q: <strong>Which algorithm or algorithms would be most appropriate for planning problems where it is important to find only optimal plans?</strong></p> <p>In this case I would go for a simple <code class="language-plaintext highlighter-rouge">UCS</code>. While <code class="language-plaintext highlighter-rouge">A* with Max Level</code> could also be an option, I cannot find a justification on why to use it instead of UCS (or even BFS), unless the problem had some boundaries or a more complex path to find the solution. UCS finds the optimal path and behaves well with small and large domains.</p>]]></content><author><name></name></author><category term="learning"/><category term="ai"/><category term="search"/><summary type="html"><![CDATA[this post is a comparison of the performance of various uninformed and informed search algorithms]]></summary></entry></feed>